<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Fundamentals: Detailed Summary</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 2em;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        strong {
            color: #e74c3c;
        }
        code {
            background: #f9f9f9;
            padding: 0.2em;
            border-radius: 3px;
        }
    </style>
</head>
<body>
    <h1>Neural Network Fundamentals: Detailed Summary</h1>

    <h2>1. Perceptron Units</h2>
    <p><strong>Perceptron</strong>: The basic building block of neural networks.</p>
    <ul>
        <li><strong>Inputs</strong> are real values that feed into the perceptron.</li>
        <li>The <strong>Bias (b)</strong> represents a threshold value used to trigger the perceptron.</li>
        <li><strong>Activation Functions</strong> are used to trigger the neuron, determining whether the perceptron "fires".</li>
        <li>The <strong>weights</strong> and <strong>bias</strong> are key parameters that determine the perceptron's output.</li>
    </ul>
    <p>The goal is to compute a linear combination of the inputs using weights and bias and pass the result through an activation function.</p>

    <h2>2. Parameters of a Network</h2>
    <ul>
        <li>Given a network architecture, the parameters are <strong>weights</strong> and <strong>biases</strong> connecting neurons.</li>
        <li>The goal of <strong>training</strong> is to learn these parameters so that the network computes the desired function accurately.</li>
        <li><strong>Weights</strong> represent the strength of connections between neurons, while <strong>biases</strong> help in shifting the activation function to better fit the data.</li>
    </ul>

    <h2>3. Learning a Network</h2>
    <ul>
        <li>The learning process aims to <strong>minimize the error</strong> between the predicted output and the desired target output.</li>
        <li>The network adjusts the weights and biases using optimization techniques to reduce this error.</li>
        <li><strong>Empirical Error</strong>: The average error over the training set is used as an estimate of the overall error.</li>
        <li>The goal is to minimize this empirical error, typically using a <strong>gradient-based optimization</strong> method.</li>
    </ul>

    <h2>4. Perceptron Algorithm</h2>
    <p>The <strong>Perceptron Learning Rule</strong> iteratively updates weights to minimize errors.</p>
    <ol>
        <li><strong>Step 1</strong>: Randomly initialize the weights and bias.</li>
        <li><strong>Step 2</strong>: Feed training inputs into the perceptron.</li>
        <li><strong>Step 3</strong>: Calculate the output using the current weights and bias.</li>
        <li><strong>Step 4</strong>: <strong>Update weights</strong> based on errors:<br>
            If output is incorrect, adjust the weights using the formula:
            <pre>⟨ Δw = η (T - O) ⟩</pre>
            where <strong>η</strong> is the learning rate, <strong>T</strong> is the target output, and <strong>O</strong> is the current output.
        </li>
        <li><strong>Step 5</strong>: Repeat until the perceptron learns to correctly classify all inputs.</li>
    </ol>
    <p><strong>Classification Rule</strong>:</p>
    <ul>
        <li>If the weighted sum is above the bias threshold, output <strong>+1</strong> (positive class).</li>
        <li>If below, output <strong>-1</strong> (negative class).</li>
    </ul>
    <p>If the classes are <strong>linearly separable</strong>, the perceptron algorithm is guaranteed to converge after a finite number of steps.</p>

    <h2>5. Activation Functions</h2>
    <p>Activation functions determine the output of a neuron and introduce <strong>non-linearity</strong> into the network, allowing it to learn complex functions.</p>
    <ul>
        <li><strong>Sigmoid</strong>:
            <ul>
                <li>Maps input values to the range <strong>[0, 1]</strong>.</li>
                <li><strong>Drawbacks</strong>: Saturation (kills gradients), not zero-centered, computationally expensive.</li>
            </ul>
        </li>
        <li><strong>Tanh</strong>:
            <ul>
                <li>Squashes input values to <strong>[-1, 1]</strong>.</li>
                <li><strong>Zero-centered</strong> output, often preferred over Sigmoid.</li>
            </ul>
        </li>
        <li><strong>ReLU (Rectified Linear Unit)</strong>:
            <ul>
                <li>Maps inputs to <strong>[0, +∞]</strong>.</li>
                <li><strong>Advantages</strong>: Does not saturate, computationally efficient, faster convergence.</li>
                <li><strong>Drawbacks</strong>: Not zero-centered, potential "<strong>Dead Neurons</strong>".</li>
            </ul>
        </li>
        <li><strong>Leaky ReLU and Parametric ReLU</strong>:
            <ul>
                <li>Allows a small, non-zero gradient for negative inputs, more robust than ReLU.</li>
            </ul>
        </li>
        <li><strong>ELU (Exponential Linear Units)</strong>:
            <ul>
                <li>Allows negative values, closer to zero-mean outputs, provides robustness against noise.</li>
            </ul>
        </li>
        <li><strong>Maxout</strong>:
            <ul>
                <li>Generalizes ReLU and Leaky ReLU, does not saturate or die, requires double the parameters per neuron.</li>
            </ul>
        </li>
    </ul>

    <h2>6. Differentiable Activation and Error Functions</h2>
    <ul>
        <li><strong>Differentiable Activation Functions</strong> are required for gradient-based optimization.</li>
        <li>The <strong>Continuous Error Function</strong> allows the network to effectively compute the <strong>gradient</strong> of the loss function and update the weights accordingly.</li>
    </ul>

    <h2>7. Vector Activation Function</h2>
    <ul>
        <li>Used for <strong>multi-class classification</strong> problems.</li>
        <li>Commonly involves the <strong>softmax</strong> function, which converts logits into <strong>probabilities</strong> over different classes.</li>
        <li>If the output value (<strong>zk</strong>) is much larger than others, <strong>softmax(zk)</strong> ≈ <strong>1</strong>, effectively behaving like an <strong>argmax</strong> function.</li>
    </ul>

    <h2>Summary of Best Practices for Activation Functions</h2>
    <ul>
        <li><strong>ReLU</strong> is recommended as the default due to its efficiency and simplicity.</li>
        <li>Consider <strong>Leaky ReLU</strong>, <strong>Maxout</strong>, or <strong>ELU</strong> for better results, especially if facing issues with dead neurons.</li>
        <li>Avoid using <strong>Sigmoid</strong> due to its drawbacks, unless required for specific scenarios.</li>
        <li><strong>Tanh</strong> can be useful if zero-centered output is needed.</li>
    </ul>

    <hr>
    <p>This summary provides an in-depth understanding of key neural network concepts, focusing on the perceptron, training methodology, activation functions, and best practices. Each major section provides critical details about the components that make up a neural network, making it easier to study and revise the material thoroughly.</p>
    <p>Let me know if you need further elaboration on any section or if you want illustrations for a specific concept!</p>
</body>
</html>
